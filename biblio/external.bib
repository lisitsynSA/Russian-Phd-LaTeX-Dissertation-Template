Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Nethercote2007a,
abstract = {Dynamic binary instrumentation (DBI) frameworks make it easy to build dynamic binary analysis (DBA) tools such as checkers and profilers. Much of the focus on DBI frameworks has been on performance; little attention has been paid to their capabilities. As a result, we believe the potential of DBI has not been fully exploited. In this paper we describe Valgrind, a DBI framework designed for building heavyweight DBA tools. We focus on its unique support for shadow values-a powerful but previously little-studied and difficult-to-implement DBA technique, which requires a tool to shadow every register and memory value with another value that describes it. This support accounts for several crucial design features that distinguish Valgrind from other DBI frameworks. Because of these features, lightweight tools built with Valgrind run comparatively slowly, but Valgrind can be used to build more interesting, heavyweight tools that are difficult or impossible to build with other DBI frameworks such as Pin and DynamoRIO. Copyright {\textcopyright} 2007 ACM.},
author = {Nethercote, Nicholas and Seward, Julian},
booktitle = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
doi = {10.1145/1250734.1250746},
title = {{Valgrind: A framework for heavyweight dynamic binary instrumentation}},
year = {2007}
}
@inproceedings{Li2019,
abstract = {Nowadays, many applications use GPUs (Graphics Processing Units) to achieve high performance. When we use GPU servers, the idle CPU resource of the servers is often ignored. In this paper, we explore the idea: using the idle CPU resource to speed up GPU programs. We design a dynamic binary optimization framework for accelerating GPU computing at runtime. A template-based binary optimization method is proposed to optimize kernels, which can avoid the high cost of kernel compilation. This method replaces determined variables with constant values and generates an optimized binary kernel. Based on the analysis results of optimization opportunities, we replace the original kernels with optimized kernels during program execution. The experimental results show that it is feasible to accelerate GPU programs via binary optimization. After applying binary optimization to five convolution layers of deep neural networks, the average performance improvement can reach 20{\%}.},
author = {Li, Guangli and Liu, Lei and Feng, Xiaobing},
booktitle = {CGO 2019 - Proceedings of the 2019 IEEE/ACM International Symposium on Code Generation and Optimization},
doi = {10.1109/CGO.2019.8661168},
title = {{Accelerating GPU Computing at Runtime with Binary Optimization}},
year = {2019}
}
@inproceedings{Khan2021a,
abstract = {Modern data center applications have deep software stacks, with instruction footprints that are orders of magnitude larger than typical instruction cache (I-cache) sizes. To efficiently prefetch instructions into the I-cache despite large application footprints, modern server-class processors implement a decoupled frontend with Fetch Directed Instruction Prefetching (FDIP). In this work, we first characterize the limitations of a decoupled frontend processor with FDIP and find that FDIP suffers from significant Branch Target Buffer (BTB) misses. We also find that existing techniques (e.g., stream prefetchers and predecoders) are unable to mitigate these misses, as they rely on an incomplete understanding of a program's branching behavior. To address the shortcomings of existing BTB prefetching techniques, we propose Twig, a novel profile-guided BTB prefetching mechanism. Twig analyzes a production binary's execution profile to identify critical BTB misses and inject BTB prefetch instructions into code. Additionally, Twig coalesces multiple non-contiguous BTB prefetches to improve the BTB's locality. Twig exposes these techniques via newBTB prefetch instructions. Since Twig prefetches BTB entries without modifying the underlying BTB organization, it is easy to adopt in modern processors. We study Twig's behavior across nine widely-used data center applications, and demonstrate that it achieves an average 20.86{\%} (up to 145{\%}) performance speedup over a baseline 8K-entry BTB, outperforming the state-of-the-art BTB prefetch mechanism by 19.82{\%} (on average).},
author = {Khan, Tanvir Ahmed and Brown, Nathan and Sriraman, Akshitha and Soundararajan, Niranjan and Kumar, Rakesh and Devietti, Joseph and Subramoney, Sreenivas and Pokam, Gilles and Litz, Heiner and Kasikci, Baris},
booktitle = {Proceedings of the Annual International Symposium on Microarchitecture, MICRO},
doi = {10.1145/3466752.3480124},
issn = {10724451},
title = {{Twig: Profile-guided BTB prefetching for data center applications}},
year = {2021}
}
@article{Moreira2021,
abstract = {Over the past few years, there has been a surge in the popularity of binary optimizers such as BOLT, Propeller, Janus and HALO. These tools use dynamic profiling information to make optimization decisions. Although effective, gathering runtime data presents developers with inconveniences such as unrepresentative inputs, the need to accommodate software modifications, and longer build times. In this paper, we revisit the static profiling technique proposed by Calder et al. in the late 90's, and investigate its application to drive binary optimizations, in the context of the BOLT binary optimizer, as a replacement for dynamic profiling. A few core modifications to Calder et al.'s original proposal, consisting of new program features and a new regression model, are sufficient to enable some of the gains obtained through runtime profiling. An evaluation of BOLT powered by our static profiler on four large benchmarks (clang, GCC, MySQL and PostgreSQL) yields binaries that are 5.47 {\%} faster than the executables produced by clang -O3.},
author = {Moreira, Ang{\'{e}}lica Aparecida and Ottoni, Guilherme and {Quint{\~{a}}o Pereira}, Fernando Magno},
doi = {10.1145/3485521},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
number = {OOPSLA},
title = {{VESPA: Static profiling for binary optimization}},
volume = {5},
year = {2021}
}
@article{Licker2020,
abstract = {We present a novel framework, Duplo, for the low-level post-link optimisation of OCaml programs, achieving a speedup of 7{\%} and a reduction of at least 15{\%} of the code size of widely-used OCaml applications. Unlike existing post-link optimisers, which typically operate on target-specific machine code, our framework operates on a Low-Level Intermediate Representation (LLIR) capable of representing both the OCaml programs and any C dependencies they invoke through the foreign-function interface (FFI). LLIR is analysed, transformed and lowered to machine code by our post-link optimiser, LLIR-OPT. Most importantly, LLIR allows the optimiser to cross the OCaml-C language boundary, mitigating the overhead incurred by the FFI and enabling analyses and transformations in a previously unavailable context. The optimised IR is then lowered to amd64 machine code through the existing target-specific code generator of LLVM, modified to handle garbage collection just as effectively as the native OCaml backend. We equip our optimiser with a suite of SSA-based transformations and points-to analyses capable of capturing the semantics and representing the memory models of both languages, along with a cross-language inliner to embed C methods into OCaml callers. We evaluate the gains of our framework, which can be attributed to both our optimiser and the more sophisticated amd64 backend of LLVM, on a wide-range of widely-used OCaml applications, as well as an existing suite of micro- and macro-benchmarks used to track the performance of the OCaml compiler.},
author = {Licker, Nandor and Jones, Timothy M.},
doi = {10.1145/3408980},
issn = {24751421},
journal = {Proceedings of the ACM on Programming Languages},
number = {ICFP},
title = {{Duplo: A framework for OCaml post-link optimisation}},
volume = {4},
year = {2020}
}
@inproceedings{Gadioli2018,
abstract = {Configuring program parallelism and selecting optimal compiler options according to the underlying platform architecture is a difficult task. Tipically, this task is either assigned to the programmer or done by a standard one-fits-all policy generated by the compiler or runtime system. A runtime selection of the best configuration requires the insertion of a lot of glue code for profiling and runtime selection. This represents a programming wall for application developers. This paper presents a structured approach, called SOCRATES, based on an aspect-oriented language (LARA) and a runtime autotuner (mARGOt) to mitigate this problem. LARA has been used to hide the glue code insertion, thus separating the pure functional application description from extra-functional requirements. mARGOT has been used for the automatic selection of the best configuration according to the runtime evolution of the application. 1},
author = {Gadioli, Davide and Nobre, Ricardo and Pinto, Pedro and Vitali, Emanuele and Ashouri, Amir H. and Palermo, Gianluca and Cardoso, Joao and Silvano, Cristina},
booktitle = {Proceedings of the 2018 Design, Automation and Test in Europe Conference and Exhibition, DATE 2018},
doi = {10.23919/DATE.2018.8342183},
title = {{SOCRATES - A seamless online compiler and system runtime autotuning framework for energy-aware applications}},
volume = {2018-Janua},
year = {2018}
}
@article{Newell2020,
abstract = {Basic block reordering is an important step for profile-guided binary optimization. The state-of-the-art goal for basic block reordering is to maximize the number of fall-through branches. However, we demonstrate that such orderings may impose suboptimal performance on instruction and I-TLB caches. We propose a new algorithm that relies on a model combining the effects of fall-through and caching behavior. As details of modern processor caching is quite complex and often unknown, we show how to use machine learning in selecting parameters that best trade off different caching effects to maximize binary performance. An extensive evaluation on a variety of applications, including Facebook production workloads, the open-source compilers Clang and GCC, and SPEC CPU benchmarks, indicate that the new method outperforms existing block reordering techniques, improving the resulting performance of applications with large code size. We have open sourced the code of the new algorithm as a part of a post-link binary optimization tool, BOLT.},
author = {Newell, Andy and Pupyrev, Sergey},
doi = {10.1109/TC.2020.2982888},
issn = {15579956},
journal = {IEEE Transactions on Computers},
number = {12},
title = {{Improved Basic Block Reordering}},
volume = {69},
year = {2020}
}
@article{Hazelwood2006,
abstract = {Dynamic binary optimizers store altered copies of original program instructions in softwaremanaged code caches in order to maximize reuse of transformed code. Code caches store code blocks that may vary in size, reference other code blocks, and carry a high replacement overhead. These unique constraints reduce the effectiveness of conventional cache management policies. Our work directly addresses these unique constraints and presents several contributions to the code-cache management problem. First, we show that evicting more than the minimum number of code blocks from the code cache results in less run-time overhead than the existing alternatives. Such granular evictions reduce overall execution time, as the fixed costs of invoking the eviction mechanism are amortized across multiple cache insertions. Second, a study of the ideal lifetimes of dynamically generated code blocks illustrates the benefit of a replacement algorithm based on a generational heuristic. We describe and evaluate a generational approach to code cache management that makes it easy to identify long-lived code blocks and simultaneously avoid any fragmentation because of the eviction of short-lived blocks. Finally, we present results from an implementation of our generational approach in the DynamoRIO framework and illustrate that, as dynamic optimization systems become more prevalent, effective code cache-management policies will be essential for reliable, scalable performance of modern applications. {\textcopyright} 2006, ACM. All rights reserved.},
author = {Hazelwood, Kim and Smith, Michael D.},
doi = {10.1145/1162690.1162692},
issn = {15443973},
journal = {ACM Transactions on Architecture and Code Optimization},
number = {3},
title = {{Managing Bounded Code Caches in Dynamic Binary Optimization Systems}},
volume = {3},
year = {2006}
}
@inproceedings{Panchenko2021,
abstract = {Profile-guided binary optimization has proved to be an important technology to achieve peak performance, particularly for large-scale binaries that are typical for data-center applications. By applying the profile data at the same representation where sampling-based profiling is collected, binary optimizers can provide double-digit speedups over binaries compiled with profile-guided optimizations using similarly collected profile data. The main blocker for adoption of binary optimizers in practice is the overhead that they add to the already long and demanding build pipelines used for producing highly optimized binaries, which already include aggressive compiler optimizations guided by profile data and also link-time optimizations. This paper addresses the overheads of binary optimizers in the context of BOLT, a modern and powerful open-source binary optimizer. More specifically, this paper describes Lightning BOLT, which is an improved version of the BOLT binary optimizer that drastically reduces BOLT's processing time and memory requirements, while preserving BOLT's effectiveness in improving the final binary's performance. Using a set of real-world data-center and open-source applications, we show that Lightning BOLT speeds up BOLT's processing by an average of 4.71× and reduces BOLT's memory consumption by 70.5{\%} on average. Furthermore, Lightning BOLT also provides an adjustable mechanism to further reduce BOLT's overheads at the cost of some lost performance for the final binary.},
author = {Panchenko, Maksim and Auler, Rafael and Sakka, Laith and Ottoni, Guilherme},
booktitle = {CC 2021 - Proceedings of the 30th ACM SIGPLAN International Conference on Compiler Construction},
doi = {10.1145/3446804.3446843},
title = {{Lightning BOLT: Powerful, fast, and scalable binary optimization}},
year = {2021}
}
@inproceedings{Ball1993,
abstract = {Many compilers rely on branch prediction to improve program performance by identifying frequently executed regions and by aiding in scheduling instructions. Profile-based predictors require a time-consuming and inconvenient compile-profile-compile cycle in order to make predictions. We present a program-based branch predictor that performs well for a large and diverse set of programs written in C and Fortran. In addition to using natural loop analysis to predict branches that control the iteration of loops, we focus on heuristics for predicting non-loop branches, which dominate the dynamic branch count of many programs. The heuristics are simple and require little program analysis, yet they are effective in terms of coverage and miss rate. Although program-based prediction does not equal the accuracy of profile-based prediction, we believe it reaches a sufficiently high level to be useful. Additional type and semantic information available to a compiler would enhance our heuristics.},
author = {Ball, Thomas and Larus, James R.},
doi = {10.1145/155090.155119},
title = {{Branch prediction for free}},
year = {1993}
}
@inproceedings{Blem2013,
abstract = {RISC vs. CISC wars raged in the 1980s when chip area and processor design complexity were the primary constraints and desktops and servers exclusively dominated the computing landscape. Today, energy and power are the primary design constraints and the computing landscape is significantly different: growth in tablets and smartphones running ARM (a RISC ISA) is surpassing that of desktops and laptops running x86 (a CISC ISA). Further, the traditionally low-power ARM ISA is entering the high-performance server market, while the traditionally high-performance x86 ISA is entering the mobile low-power device market. Thus, the question of whether ISA plays an intrinsic role in performance or energy efficiency is becoming important, and we seek to answer this question through a detailed measurement based study on real hardware running real applications. We analyze measurements on the ARM Cortex-A8 and Cortex-A9 and Intel Atom and Sandybridge i7 microprocessors over workloads spanning mobile, desktop, and server computing. Our methodical investigation demonstrates the role of ISA in modern microprocessors' performance and energy efficiency. We find that ARM and x86 processors are simply engineering design points optimized for different levels of performance, and there is nothing fundamentally more energy efficient in one ISA class or the other. The ISA being RISC or CISC seems irrelevant. {\textcopyright} 2013 IEEE.},
author = {Blem, Emily and Menon, Jaikrishnan and Sankaralingam, Karthikeyan},
booktitle = {Proceedings - International Symposium on High-Performance Computer Architecture},
doi = {10.1109/HPCA.2013.6522302},
issn = {15300897},
title = {{Power struggles: Revisiting the RISC vs. CISC debate on contemporary ARM and x86 architectures}},
year = {2013}
}
@inproceedings{Rimsa2019,
abstract = {The extraction of high-level information from binary code is an important problem in programming languages, whose solution supports the detection of malware in binary code and the construction of dynamic program slices. The Control Flow Graph is one of the instruments used to represent the structure of binary programs. Most solutions to reconstruct CFGs from binary programs rely on purely static techniques, based either on data-flow analyses, or in type inference. In contrast, in this work we use a purely dynamic approach to such a purpose. Our technique can be used alone, or in combination with static analysis tools. We demonstrate that it is possible to verify completeness in several real-world programs. We also show how to combine our technique with DynInst, the current state-of-the-art static CFG reconstructor. By providing DynInst with extra information, we improve its capacity to deal with indirect jumps. Our dynamic CFG reconstructor has been implemented on top of valgrind. When applied on cBench, this implementation is able to completely cover 36{\%} of all the functions available in that suite. It adds an average overhead of 43x onto the execution of the original programs. Although expressive, this overhead is almost four times lower than the overhead of DCFG, a tool distributed by Intel, and built on top of PinPlay.},
author = {Rimsa, Andrei and Amaral, Jos{\'{e}} Nelson and Quint{\~{a}}o, Fernando Magno},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3355378.3355383},
title = {{Efficient and precise dynamic construction of control flow graphs}},
year = {2019}
}
@inproceedings{Desmet2005,
abstract = {Improving static branch prediction accuracy is an important problem with various interesting applications. First, several compiler optimizations such as code layout, scheduling, predication, etc. rely on accurate static branch prediction. Second, branches that are statically accurately predictable can be removed from the dynamic branch predictor thereby reducing aliasing. Third, for embedded microprocessors which lack dynamic branch prediction, static branch prediction is the only alternative. This paper builds on previous work done on evidence-based static branch prediction which uses decision trees to classify branches. We demonstrate how decision trees can be used to improve the Ball and Larus heuristics by optimizing the sequence of applying the heuristics and by discovering two new heuristics, namely one based on the post-domination relationship between the current basic block and its successor and one based on the dependency distance between the branch and its operand defining instruction. Experimental results indicate an increase in the number of instructions per mispredicted branch by 18.5{\%} on average for SPECint95 and SPECint2000. In addition, we show that decision trees can improve profile-based static branch prediction by up to 11.7{\%} by predicting branches that are unseen in the profile runs. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
author = {Desmet, Veerle and Eeckhout, Lieven and {De Bosschere}, Koen},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/11572961_27},
issn = {03029743},
title = {{Using decision trees to improve program-based and profile-based static branch prediction}},
volume = {3740 LNCS},
year = {2005}
}
@misc{Ashouri2018,
abstract = {Since the mid-1990s, researchers have been trying to use machine-learning-based approaches to solve a number of different compiler optimization problems. These techniques primarily enhance the quality of the obtained results and, more importantly, make it feasible to tackle two main compiler optimization problems: optimization selection (choosing which optimizations to apply) and phase-ordering (choosing the order of applying optimizations). The compiler optimization space continues to grow due to the advancement of applications, increasing number of compiler optimizations, and new target architectures. Generic optimization passes in compilers cannot fully leverage newly introduced optimizations and, therefore, cannot keep up with the pace of increasing options. This survey summarizes and classifies the recent advances in using machine learning for the compiler optimization field, particularly on the two major problems of (1) selecting the best optimizations, and (2) the phase-ordering of optimizations. The survey highlights the approaches taken so far, the obtained results, the fine-grain classification among different approaches, and finally, the influential papers of the field.},
author = {Ashouri, Amir H. and Killian, William and Cavazos, John and Palermo, Gianluca and Silvano, Cristina},
booktitle = {ACM Computing Surveys},
doi = {10.1145/3197978},
issn = {15577341},
number = {5},
title = {{A survey on compiler autotuning using machine learning}},
volume = {51},
year = {2018}
}
@inproceedings{Khan2021,
abstract = {Modern data center applications exhibit deep software stacks, resulting in large instruction footprints that frequently cause instruction cache misses degrading performance, cost, and energy efficiency. Although numerous mechanisms have been proposed to mitigate instruction cache misses, they still fall short of ideal cache behavior, and furthermore, introduce significant hardware overheads. We first investigate why existing I-cache miss mitigation mechanisms achieve sub-optimal performance for data center applications. We find that widely-studied instruction prefetchers fall short due to wasteful prefetch-induced cache line evictions that are not handled by existing replacement policies. Existing replacement policies are unable to mitigate wasteful evictions since they lack complete knowledge of a data center application's complex program behavior.To make existing replacement policies aware of these eviction-inducing program behaviors, we propose Ripple, a novel software-only technique that profiles programs and uses program context to inform the underlying replacement policy about efficient replacement decisions. Ripple carefully identifies program con-texts that lead to I-cache misses and sparingly injects "cache line eviction"instructions in suitable program locations at link time. We evaluate Ripple using nine popular data center applications and demonstrate that Ripple enables any replacement policy to achieve speedup that is closer to that of an ideal I-cache. Specifically, Ripple achieves an average performance improvement of 1.6{\%} (up to 2.13{\%}) over prior work due to a mean 19{\%} (up to 28.6{\%}) I-cache miss reduction.},
author = {Khan, Tanvir Ahmed and Zhang, Dexin and Sriraman, Akshitha and Devietti, Joseph and Pokam, Gilles and Litz, Heiner and Kasikci, Baris},
booktitle = {Proceedings - International Symposium on Computer Architecture},
doi = {10.1109/ISCA52012.2021.00063},
issn = {10636897},
title = {{Ripple: Profile-guided instruction cache replacement for data center applications}},
volume = {2021-June},
year = {2021}
}
@article{Bruening2004,
abstract = {This thesis addresses the challenges of building a software system for general-purpose runtime code manipulation. Modern applications, with dynamically-loaded modules and dynamicallygenerated code, are assembled at runtime. While it was once feasible at compile time to observe and manipulate every instruction  which is critical for program analysis, instrumentation, trace gathering, optimization, and similar tools  it can now only be done at runtime. Existing runtime tools are successful at inserting instrumentation calls, but no general framework has been developed for ne-grained and comprehensive code observation and modication without high overheads. This thesis demonstrates the feasibility of building such a system in software. We present DynamoRIO, a fully-implemented runtime code manipulation system that supports code transformations on any part of a program, while it executes. DynamoRIO uses code caching technology to provide efcient, transparent, and comprehensive manipulation of an unmodied application running on a stock operating system and commodity hardware. DynamoRIO executes large, complex, modern applications with dynamically-loaded, generated, or even modied code. Despite the formidable obstacles inherent in the IA-32 architecture, DynamoRIO provides these capabilities efciently, with zero to thirty percent time and memory overhead on both Windows and Linux. DynamoRIO exports an interface for building custom runtime code manipulation tools of all types. It has been used by many researchers, with several hundred downloads of our public release, and is being commercialized in a product for protection against remote security exploits, one of numerous applications of runtime code manipulation.},
author = {Bruening, Derek},
journal = {Electrical Engineering},
title = {{Efficient, transparent, and comprehensive runtime code manipulation}},
year = {2004}
}
@article{Neves2021,
abstract = {The performance of modern processors is often limited by execution stalls resulting from long memory access latencies. Compile-time optimizations, deep cache hierarchies and prefetching mechanisms already provide significant performance gains, by performing memory accesses in parallel with computation. However, they are reaching a throughput improvement limit. Hence, new solutions that effectively exploit the memory access patterns to improve processing throughput are required. To achieve this objective, a new compiler-assisted data streaming method is proposed. It leverages static analysis and code transformations with an on-chip data streaming support as a viable alternative to prefetching mechanisms for regular code structures. Static analysis is used to identify and encode memory accesses with a dedicated representation. Then, a code transformation algorithm detaches data indexation and address calculation from computation, allowing for a significant code reduction. An on-chip data stream controller, attached to the L1 data cache, is used to autonomously generate memory accesses from the pattern representation and reorganize the data transfers in streams, with the aid of stream buffers. When compared with state-of-the-art prefetchers, the proposed solution provides up to 26 percent of code reduction, an IPC improvement of 2.4x, and an average performance improvement of 40 percent.},
author = {Neves, Nuno and Tomas, Pedro and Roma, Nuno},
doi = {10.1109/TC.2020.2990302},
issn = {15579956},
journal = {IEEE Transactions on Computers},
number = {3},
title = {{Compiler-Assisted Data Streaming for Regular Code Structures}},
volume = {70},
year = {2021}
}
@misc{ODea2020,
abstract = { This statistic shows the number of smartphones sold to end users worldwide from 2007 to 2021. In 2019, around 1.52 billion smartphones were sold worldwide. In the first quarter of 2020, around 86.3 percent of all smartphones sold to end users were phones with the Android operating system.

Smartphone end user sales - additional information

In 2019, the number of smartphones sold to consumers stood at around 1.52 billion units, a significant increase from the 680 million units sold in 2012. This means that over 19 percent of the world's total population owned a smart device in 2019, a figure that is expected to increase to 37 percent by 2021. In 2018 smartphone penetration reached 60.5 percent in North America.

In the United States alone, sales of smartphones were projected to be worth around 77.5 billion U.S. dollars in 2019, an increase from 18 billion dollars in 2010. By 2021, it is forecast that almost 84.3 percent of all mobile users in the United States will own a smartphone, an increase from the 27 percent of mobile users in 2010. },
author = {O'Dea, S.},
booktitle = {Statista.com},
title = {{ Global smartphone sales to end users 2007-2021}},
year = {2020}
}
@inproceedings{Savage2020,
abstract = {Today, general-purpose memory allocators dominate the landscape of dynamic memory management. While these solutions can provide reasonably good behaviour across a wide range of workloads, it is an unfortunate reality that their behaviour for any particular workload can be highly suboptimal. By catering primarily to average and worst-case usage patterns, these allocators deny programs the advantages of domain-specific optimisations, and thus may inadvertently place data in a manner that hinders performance, generating unnecessary cache misses and load stalls. To help alleviate these issues, we propose HALO: a postlink profile-guided optimisation tool that can improve the layout of heap data to reduce cache misses automatically. Profiling the target binary to understand how allocations made in different contexts are related, we specialise memorymanagement routines to allocate groups of related objects from separate pools to increase their spatial locality. Unlike other solutions of its kind, HALO employs novel grouping and identification algorithms which allow it to create tight-knit allocation groups using the entire call stack and to identify these efficiently at runtime. Evaluation of HALO on contemporary out-of-order hardware demonstrates speedups of up to 28{\%} over jemalloc, out-performing a state-of-theart data placement technique from the literature.},
author = {Savage, Joe and Jones, Timothy M.},
booktitle = {CGO 2020 - Proceedings of the 18th ACM/IEEE International Symposium on Code Generation and Optimization},
doi = {10.1145/3368826.3377914},
title = {{HALO: Post-link heap-layout optimisation}},
year = {2020}
}
@inproceedings{Fisher1992,
abstract = {There are several important reasons for predicting which way the flow of control of a program is going to go: first, in instruction-level parallel architectures, code motions can produce more data-ready candidate instructions at once than there are resources to execute them. Some of these are speculative (executed ahead of a conditional branch that might otherwise have prevented their execution), so one must sensibly pick among them, and one must avoid issuing low probability speculative instructions when the system overhead associated with canceling them most of the time outweighs the gain of their infrequent success; second, important classes of compiler optimizations depend upon this information; and finally, branch prediction can help optimize pipelined fetch and execute, icache fill, etc. If substantial code motions are desired, it is probably impractical to expect the hardware to make them, and a compiler must instead. Thus, the compiler must have access to branch predictions made before the program runs. In this paper we consider the question of how predictable branches are when previous runs of a program are used to feed back information to the compiler. We propose new measures which we believe more clearly capture the predictability of branches in programs. We find that even code with a complex flow of control, including systems utilities and language processors written in C, are dominated by branches which go in one way, and that this direction usually varies little when one changes the data used as the predictor and target.},
author = {Fisher, Joseph A. and Freudenberger, Stefan M.},
booktitle = {International Conference on Architectural Support for Programming Languages and Operating Systems - ASPLOS},
doi = {10.1145/143371.143493},
issn = {15581160},
number = {9},
title = {{Predicting conditional branch directions from previous runs of a program}},
volume = {27},
year = {1992}
}
@article{Al-Tashi2019,
abstract = {A binary version of the hybrid grey wolf optimization (GWO) and particle swarm optimization (PSO) is proposed to solve feature selection problems in this paper. The original PSOGWO is a new hybrid optimization algorithm that benefits from the strengths of both GWO and PSO. Despite the superior performance, the original hybrid approach is appropriate for problems with a continuous search space. Feature selection, however, is a binary problem. Therefore, a binary version of hybrid PSOGWO called BGWOPSO is proposed to find the best feature subset. To find the best solutions, the wrapper-based method K-nearest neighbors classifier with Euclidean separation matric is utilized. For performance evaluation of the proposed binary algorithm, 18 standard benchmark datasets from UCI repository are employed. The results show that BGWOPSO significantly outperformed the binary GWO (BGWO), the binary PSO, the binary genetic algorithm, and the whale optimization algorithm with simulated annealing when using several performance measures including accuracy, selecting the best optimal features, and the computational time.},
author = {Al-Tashi, Qasem and {Abdul Kadir}, Said Jadid and Rais, Helmi Md and Mirjalili, Seyedali and Alhussian, Hitham},
doi = {10.1109/ACCESS.2019.2906757},
issn = {21693536},
journal = {IEEE Access},
title = {{Binary Optimization Using Hybrid Grey Wolf Optimization for Feature Selection}},
volume = {7},
year = {2019}
}
@article{Valiante2021,
abstract = {Recently, there has been considerable interest in solving optimization problems by mapping these onto a binary representation, sparked mostly by the use of quantum annealing machines. Such binary representation is reminiscent of a discrete physical two-state system, such as the Ising model. As such, physics-inspired techniques—commonly used in fundamental physics studies—are ideally suited to solve optimization problems in a binary format. While binary representations can be often found for paradigmatic optimization problems, these typically result in k-local higher-order unconstrained binary optimization cost functions. In this work, we discuss the effects of locality reduction needed for the majority of the currently available quantum and quantum-inspired solvers that can only accommodate 2-local (quadratic) cost functions. General locality reduction approaches require the introduction of ancillary variables which cause an overhead over the native problem. Using a parallel tempering Monte Carlo solver on Microsoft Azure Quantum, as well as k-local binary problems with planted solutions, we show that post reduction to a corresponding 2-local representation the problems become considerably harder to solve. We further quantify the increase in computational hardness introduced by the reduction algorithm by measuring the variation of number of variables, statistics of the coefficient values, and the population annealing entropic family size. Our results demonstrate the importance of avoiding locality reduction when solving optimization problems.},
author = {Valiante, Elisabetta and Hernandez, Maritza and Barzegar, Amin and Katzgraber, Helmut G.},
doi = {10.1016/j.cpc.2021.108102},
issn = {00104655},
journal = {Computer Physics Communications},
title = {{Computational overhead of locality reduction in binary optimization problems}},
volume = {269},
year = {2021}
}
@article{Pereira2019,
abstract = {A store operation is called "silent" if it writes in memory a value that is already there. The ability to detect silent stores is important, because they might indicate performance bugs, might enable code optimizations, and might reveal opportunities of automatic parallelization, for instance. Silent stores are traditionally detected via profiling tools. In this article, we depart from this methodology and instead explore the following question: Is it possible to predict silentness by analyzing the syntax of programs? The process of building an answer to this question is interesting in itself, given the stochastic nature of silent stores, which depend on data and coding style. To build such an answer, we have developed a methodology to classify store operations in terms of syntactic features of programs. Based on such features, we develop different kinds of predictors, some of which go much beyond what any trivial approach could achieve. To illustrate how static prediction can be employed in practice, we use it to optimize programs running on nonvolatile memory systems.},
author = {Pereira, Fernando Magno Quint{\~{a}}o and Leobas, Guilherme Vieira and Gamati{\'{e}}, Abdoulaye},
doi = {10.1145/3280848},
issn = {15443973},
journal = {ACM Transactions on Architecture and Code Optimization},
number = {4},
title = {{Static prediction of silent stores}},
volume = {15},
year = {2019}
}
@article{Rimsa2021,
abstract = {The automatic recovery of a program's high-level representation from its binary version is a well-studied problem in programming languages. However, most of the solutions to this problem are based on purely static approaches: techniques such as dataflow analyses or type inference are used to convert the bytes that constitute the executable code back into a control flow graph (CFG). This article departs from such a modus operandi to show that a dynamic analysis can be effective and useful, both as a standalone technique, and as a way to enhance the precision of static approaches. The experimental results provide evidence that completeness, that is, the ability to conclude that the entire CFG has been discovered, is achievable on many functions that are part of industry-strong benchmarks. Experiments also indicate that dynamic information greatly enhances the ability of DynInst, a state-of-the-art binary reconstructor, to deal with code stripped of debugging information. These results were obtained with CFGgrind, a new implementation of a dynamic code reconstructor, built on top of Valgrind. When applied to cBench, CFGgrind is 9{\%} faster than callgrind, Valgrind's tool used to track targets of function calls; and 7{\%} faster in Spec Cpu2017. CFGgrind recovers the complete CFG of 40{\%} of all the procedures invoked during the standard execution of programs in Spec Cpu2017, and 37{\%} in cBench. When combined with CFGgrind, DynInst finds 15{\%} more CFGs for cBench, and 7{\%} more CFGs for Spec Cpu2017. Finally, CFGgrind is more than 7 times faster than DCFG, a CFG reconstructor from Intel, and 1.30 times faster than bfTrace, a CFG reconstructor used in research. CFGgrind is also more precise than these two tools, handling operating system signals, shared code in functions, and unaligned instructions; besides supporting multithreaded programs, exact profiling and incremental refinements.},
author = {Rimsa, Andrei and {Nelson Amaral}, Jos{\'{e}} and Pereira, Fernando M.Q.},
doi = {10.1002/spe.2907},
issn = {1097024X},
journal = {Software - Practice and Experience},
number = {2},
title = {{Practical dynamic reconstruction of control flow graphs}},
volume = {51},
year = {2021}
}
@article{Nethercote2007,
abstract = {Dynamic binary instrumentation (DBI) frameworks make it easy to build dynamic binary analysis (DBA) tools such as checkers and profilers. Much of the focus on DBI frameworks has been on performance; little attention has been paid to their capabilities. As a result, we believe the potential of DBI has not been fully exploited. In this paper we describe Valgrind, a DBI framework designed for building heavyweight DBA tools. We focus on its unique support for shadow values-a powerful but previously little-studied and difficult-to-implement DBA technique, which requires a tool to shadow every register and memory value with another value that describes it. This support accounts for several crucial design features that distinguish Valgrind from other DBI frameworks. Because of these features, lightweight tools built with Valgrind run comparatively slowly, but Valgrind can be used to build more interesting, heavyweight tools that are difficult or impossible to build with other DBI frameworks such as Pin and DynamoRIO. {\textcopyright} 2007 ACM.},
author = {Nethercote, Nicholas and Seward, Julian},
doi = {10.1145/1273442.1250746},
issn = {15232867},
journal = {ACM SIGPLAN Notices},
number = {6},
title = {{Valgrind: A framework for heavyweight dynamic binary instrumentation}},
volume = {42},
year = {2007}
}
@inproceedings{Smith1981,
abstract = {In high-performance computer systems, performance losses due to conditional branch instructions can be minimized by predicting a branch outcome and fetching, decoding, and/or issuing subsequent instructions before the actual outcome is known. This paper discusses branch prediction strategies with the goal of maximizing prediction accuracy. First, currently used techniques are discussed and analyzed using instruction trace data. Then, new techniques are proposed and are shown to provide greater accuracy and more flexibility at low cost.},
author = {Smith, James E.},
booktitle = {Proceedings - International Symposium on Computer Architecture},
doi = {10.1145/285930.285980},
issn = {10636897},
title = {{A study of branch prediction strategies}},
year = {1981}
}
@inproceedings{Ottoni2021,
abstract = {Just-In-Time (JIT) compilation is often employed in Virtual Machines (VMs) to translate their virtual-machine languages into real-machine code. This approach not only brings portability, but it also enables aggressive compiler optimizations based on runtime behavior observed via profiling. The downside of JIT compilation, compared to Ahead-Of-Time native compilation, is that the profiling and compilation overheads are incurred during execution. To mitigate these overheads, previous work have proposed sharing either profile data or final JIT compiled code across VM executions. Unfortunately, these techniques have drawbacks, including steady-state performance degradation and difficulty of use. To address these issues, this paper presents the Jump-Start mechanism implemented inside the Hip Hop Virtual Machine (HHVM). Jump-Start is a practical approach to share VM profile data at a large scale, being used to power one of the largest websites in the world. In this paper, we argue for HHVM's Jump-Start approach, describe it in detail, and present steady-state optimizations built on top of it. Running the Facebook website, we demonstrate that Jump-Start effectively solves the warmup problem in HHVM, reducing the server capacity loss during warmup by 54.9{\%}, while also improving steady-state performance by 5.4{\%}.},
author = {Ottoni, Guilherme and Liu, Bin},
booktitle = {CGO 2021 - Proceedings of the 2021 IEEE/ACM International Symposium on Code Generation and Optimization},
doi = {10.1109/CGO51591.2021.9370314},
title = {{HHVM Jump-Start: Boosting Both Warmup and Steady-State Performance at Scale}},
year = {2021}
}
@inproceedings{Ottoni2017,
abstract = {Modern data-center applications often comprise a large amount of code, with substantial working sets, making them good candidates for code-layout optimizations. Although recent work has evaluated the impact of profile-guided intramodule optimizations and some cross-module optimizations, no recent study has evaluated the benefit of function placement for such large-scale applications. In this paper, we study the impact of function placement in the context of a simple tool we created that uses sample-based profiling data. By using sample-based profiling, this methodology follows the same principle behind AutoFDO, i.e. using profiling data collected from unmodified binaries running in production, which makes it applicable to large-scale binaries. Using this tool, we first evaluate the impact of the traditional Pettis-Hansen (PH) function-placement algorithm on a set of widely deployed data-center applications. Our experiments show that using the PH algorithm improves the performance of the studied applications by an average of 2.6{\%}. In addition to that, this paper also evaluates the impact of two improvements on top of the PH technique. The first improvement is a new algorithm, called C3, which addresses a fundamental weakness we identified in the PH algorithm. We not only qualitatively illustrate how C3 overcomes this weakness in PH, but also present experimental results confirming that C3 performs better than PH in practice, boosting the performance of our workloads by an average of 2.9{\%} on top of PH. The second improvement we evaluate is the selective use of huge pages. Our evaluation shows that, although aggressively mapping the entire code section of a large binary onto huge pages can be detrimental to performance, judiciously using huge pages can further improve performance of our applications by 2.0{\%} on average.},
author = {Ottoni, Guilherme and Maher, Bertrand},
booktitle = {CGO 2017 - Proceedings of the 2017 International Symposium on Code Generation and Optimization},
doi = {10.1109/CGO.2017.7863743},
title = {{Optimizing function placement for large-scale data-center applications}},
year = {2017}
}
@inproceedings{Sari2021,
abstract = {In this paper, by targeting low-level code optimization, an instruction scheduler is designed and experimented with a synergistic processor unit (SPU) to show its effectiveness on a basic block and data dependency graph (DDG) called compiler instruction scheduler (CIS). In our methodology, a source C/C++ file is converted to an assembly file via spu-gcc to detect stalls in basic code blocks and CIS generates the DDG of executable code to eliminate stalls to find optimization opportunities and increase the program performance. The CIS simply shuffles the instruction sequences of the assembly code to eliminate CPU stalls in a given basic instruction block. Random and sliding window schedulers are implemented to generate a new assembly code sequence based on DDG and a basic block in parallel. Finally, this paper describes how CIS finds the optimized code sequence for a given file without any conflicts and hazards. Compared to the original code compilation process, we have shown that CIS improves the code execution metrics, and also our evaluated speedup results are found to be promising.},
author = {Sari, Alparslan and Butun, Ismail},
booktitle = {2021 Zooming Innovation in Consumer Technologies Conference, ZINC 2021},
doi = {10.1109/ZINC52049.2021.9499298},
title = {{A Highly Scalable Instruction Scheduler Design based on CPU Stall Elimination}},
year = {2021}
}
@inproceedings{Panchenko2019,
abstract = {Performance optimization for large-scale applications has recently become more important as computation continues to move towards data centers. Data-center applications are generally very large and complex, which makes code layout an important optimization to improve their performance. This has motivated recent investigation of practical techniques to improve code layout at both compile time and link time. Although post-link optimizers had some success in the past, no recent work has explored their benefits in the context of modern data-center applications. In this paper, we present BOLT, an open-source post-link optimizer built on top of the LLVM framework. Utilizing sample-based profiling, BOLT boosts the performance of real-world applications even for highly optimized binaries built with both feedback-driven optimizations (FDO) and link-time optimizations (LTO). We demonstrate that post-link performance improvements are complementary to conventional compiler optimizations, even when the latter are done at a whole-program level and in the presence of profile information. We evaluated BOLT on both Facebook data-center workloads and open-source compilers. For data-center applications, BOLT achieves up to 7.0{\%} performance speedups on top of profile-guided function reordering and LTO. For the GCC and Clang compilers, our evaluation shows that BOLT speeds up their binaries by up to 20.4{\%} on top of FDO and LTO, and up to 52.1{\%} if the binaries are built without FDO and LTO.},
author = {Panchenko, Maksim and Auler, Rafael and Nell, Bill and Ottoni, Guilherme},
booktitle = {CGO 2019 - Proceedings of the 2019 IEEE/ACM International Symposium on Code Generation and Optimization},
doi = {10.1109/CGO.2019.8661201},
title = {{BOLT: A Practical Binary Optimizer for Data Centers and beyond}},
year = {2019}
}
@article{Hong2019,
abstract = {Region formation is an important step in dynamic binary translation to select hot code regions for translation and optimization. The quality of the formed regions determines the extent of optimizations and thus determines the final execution performance. Moreover, the overall performance is very sensitive to the formation overhead, because region formation can have a non-trivial cost. For addressing the dual issues of region quality and region formation overhead, this article presents a lightweight region formation method guided by processor tracing, e.g., Intel PT.We leverage the branch history information stored in the processor to reconstruct the program execution profile and effectively form high-quality regions with low cost. Furthermore, we present the designs of lightweight hardware performance monitoring sampling and the branch instruction decode cache to minimize region formation overhead. Using ARM64 to x86-64 translations, the experiment results show that our method achieves a performance speedup of up to 1.53× (1.16× on average) for SPEC CPU2006 benchmarks with reference inputs, compared to the well-known software-based trace formation method, Next Executing Tail (NET). The performance results of x86-64 to ARM64 translations also show a speedup of up to 1.25× over NET for CINT2006 benchmarks with reference inputs. The comparison with a relaxed NETPlus region formation method further demonstrates that our method achieves the best performance and lowest compilation overhead.},
author = {Hong, Ding Yong and Wu, Jan Jan and Liu, Yu Ping and Fu, Sheng Yu and Hsu, Wei Chung},
doi = {10.1145/3281664},
issn = {15443973},
journal = {ACM Transactions on Architecture and Code Optimization},
number = {4},
title = {{Processor-tracing guided region formation in dynamic binary translation}},
volume = {15},
year = {2019}
}
@inproceedings{Li2010,
abstract = {Cross-module inter-procedural compiler optimization (IPO) and Feedback-Directed Optimization (FDO) are two important compiler techniques delivering solid performance gains. The combination of IPO and FDO delivers peak performance, but also multiplies both techniques' usability problems. In this paper, we present LIPO, a novel static IPO framework, which integrates IPO and FDO. Compared to existing approaches, LIPO no longer requires writing of the compiler's intermediate representation, eliminates the link-time inter-procedural optimization phase entirely, and minimizes code re-generation overhead, thus improving scalability by an order of magnitude. Compared to an FDO baseline, and without further specific tuning, LIPO improves performance of SPEC2006 INT by 2.5{\%}, and of SPEC2000 INT by 4.4{\%}, with up to 23{\%} for one benchmarks. We confirm our scalability results on a set of large industrial applications, demonstrating 2.9{\%} performance improvements on average. Compile time overhead for full builds is less than 30{\%}, incremental builds take a few seconds on average, and storage requirements increase by only 24{\%}, all compared to the FDO baseline. {\textcopyright} 2010 ACM.},
author = {Li, David Xinliang and Ashok, Raksit and Hundt, Robert},
booktitle = {Proceedings of the 2010 CGO - The 8th International Symposium on Code Generation and Optimization},
doi = {10.1145/1772954.1772964},
title = {{Lightweight feedback-directed cross-module optimization}},
year = {2010}
}
@inproceedings{Fu2018,
abstract = {ARMv8 based processors are now prevalent in mobile devices while the majority of applications in Google App Store are still ARMv7 code. This causes the desire for supporting backward compatibility. Such circumstances not only complicate the hardware design but also overlook the benefits from running on new ARMv8 processors. This paper presents a software based solution for the backward compatibility via Dynamic Binary Translation (DBT). This DBT framework is able to run ARMv7 executables on pure ARMv8 devices. Moreover, by exploiting ARMv8 SIMD capabilities, the execution achieves an average speedup of 1.49 × compared to ARMv7 native run across various benchmarks.},
author = {Fu, Sheng Yu and Lin, Chih Min and Hong, Ding Yong and Liu, Yu Ping and Wu, Jan Jan and Hsu, Wei Chung},
booktitle = {2018 International Conference on Compilers, Architecture and Synthesis for Embedded Systems, CASES 2018},
doi = {10.1109/CASES.2018.8516794},
title = {{Work-in-Progress: Exploiting SIMD Capability in an ARMv7-to-ARMv8 Dynamic Binary Translator}},
year = {2018}
}
@article{Wu1994,
abstract = {Program profiles identify frequently executed portions of a program, which are the places at which optimizations offer programmers and compilers the greatest benefit. Compilers, however, infrequently exploit program profiles, because profiling a program requires a programmer to instrument and run the program. An attractive alternative is for the compiler to statically estimate program profiles.. This paper presents several new techniques for static branch prediction and profiling. The first technique combines multiple predictions of a branch's outcome into a prediction of the probability that the branch is taken. Another technique uses these predictions to estimate the relative execution frequency (i.e., profile) of basic blocks and control-flow edges within a procedure. A third algorithm uses local frequency estimates to predict the global frequency of calls, procedure invocations, and basic block and control-flow edge executions. Experiments on the SPEC92 integer benchmarks and Unix applications show that the frequently executed blocks, edges, and functions identified by our techniques closely match those in a dynamic profile.},
author = {Wu, Youfeng and Larus, James R.},
doi = {10.1109/micro.1994.717399},
issn = {09536639},
journal = {Professional Engineering},
number = {21},
title = {{Static branch frequency and program profile analysis}},
volume = {7},
year = {1994}
}
@inproceedings{Luk2004,
abstract = {Ispike is a post-link optimizer developed for the Intel{\textregistered} Itanium Processor Family (IPF) processors. The IPF architecture poses both opportunities and challenges to post-link optimizations. IPF offers a rich set of performance counters to collect detailed profile information at a low cost, which is essential to post-link optimization being practical At the same time, the predication and bundling features on IPF make post-link code transformation more challenging than on other architectures. In Ispike, we have implemented optimizations like code layout, instruction prefetching, data layout, and data prefetching that exploit the IPF advantages, and strategies that cope with the IPF-specific challenges. Using SPEC CINT2000 as benchmarks, we show that Ispike improves performance by as much as 40{\%} on the Itanium{\textregistered} 2 processor, with average improvement of 8.5{\%} and 9.9{\%} over executables generated by the Intel{\textregistered} Electron compiler and by the Gcc compiler, respectively. We also demonstrate that statistical profiles collected via IFF performance counters and complete profiles collected via instrumentation produce equal performance benefit, but the profiling overhead is significantly lower for performance counters.},
author = {Luk, Chi Keung and Muth, Robert and Patil, Harish and Cohn, Robert and Lowney, Geoff},
booktitle = {International Symposium on Code Generation and Optimization, CGO},
title = {{Ispike: A post-link optimizer for the Intel{\textregistered}Itanium{\textregistered} architecture}},
year = {2004}
}
@article{Desmond2009,
abstract = {The exploration of source code in modern integrated development environments can lead to disorientation problems due to a lack of visible exploration context as the programmer moves between successive source code displays. Inline source code exploration is a technology which facilitates the exploration of source code in context. In contrast to explicitly navigating between isolated displays of source code, the programmer fluidly introduces related source code declarations into the context of a primary or focal source code document. The inline approach provides an explicit representation of exploration context between successive source code locations, provides support for the pursuit of exploratory digressions, and allows the programmer to view multiple related source code locations simultaneously with minimal interface adjustment. In this paper we introduce inline source code exploration and describe a user experiment designed to evaluate the effectiveness of the technique at reducing the level of disorientation experienced by programmers during source code exploration activities.},
author = {Desmond, Michael and Exton, Chris},
journal = {Ppigorg},
title = {{An evaluation of the inline source code exploration technique}},
year = {2009}
}
@inproceedings{Arif2021,
abstract = {Binary instrumentation and rewriting frameworks provide a powerful way of implementing custom analysis and transformation techniques for applications ranging from performance profiling to security monitoring. However, using these frameworks to write even simple analyses and transformations is non-trivial. Developers often need to write framework-specific boilerplate code and work with low-level and complex programming details. This not only results in hundreds (or thousands) of lines of code, but also leaves significant room for error. To address this, we introduce Cinnamon, a domain-specific language designed to write programs for binary profiling and monitoring. Cinnamon's abstractions allow the programmer to focus on implementing their technique in a platform-independent way, without worrying about complex lower-level details. Programmers can use these abstractions to perform analysis and instrumentation at different locations and granularity levels in the binary. The flexibility of Cinnamon also enables its programs to be mapped to static, dynamic or hybrid analysis and instrumentation approaches. As a proof of concept, we target Cinnamon to three different binary frameworks by implementing a custom Cinnamon to C/C++ compiler and integrating the generated code within these frameworks. We further demonstrate the ability of Cinnamon to express a range of profiling and monitoring tools through different use-cases.},
author = {Arif, Mahwish and Zhou, Ruoyu and Ho, Hsi Ming and Jones, Timothy M.},
booktitle = {CGO 2021 - Proceedings of the 2021 IEEE/ACM International Symposium on Code Generation and Optimization},
doi = {10.1109/CGO51591.2021.9370313},
title = {{Cinnamon: A Domain-Specific Language for Binary Profiling and Monitoring}},
year = {2021}
}
@article{Ottoni2018,
abstract = {Dynamic languages such as PHP, JavaScript, Python, and Ruby have been gaining popularity over the last two decades. A very popular domain for these languages is web development, including server-side development of large-scale websites. As a result, improving the performance of these languages has become more important. Efficiently compiling programs in these languages is challenging, and many popular dynamic languages still lack efficient production-quality implementations. This paper describes the design of the second generation of the HHVM JIT and how it addresses the challenges to efficiently execute PHP and Hack programs. This new design uses profiling to build an aggressive region-based JIT compiler. We discuss the benefits of this approach compared to the more popular method-based and trace-based approaches to compile dynamic languages. Our evaluation running a very large PHP-based code base, the Facebook website, demonstrates the effectiveness of the new JIT design.},
author = {Ottoni, Guilherme},
doi = {10.1145/3296979.3192374},
issn = {0362-1340},
journal = {ACM SIGPLAN Notices},
number = {4},
title = {{HHVM JIT: a profile-guided, region-based compiler for PHP and Hack}},
volume = {53},
year = {2018}
}
@inproceedings{Ajorpaz2018,
abstract = {Modern processors support instruction fetch with the instruction cache (I-cache) and branch target buffer (BTB). Due to timing and area constraints, the I-cache and BTB must efficiently make use of their limited capacities. Blocks in the I-cache or entries in the BTB that have low potential for reuse should be replaced by more useful blocks/entries. This work explores predictive replacement policies based on reuse prediction that can be applied to both the I-cache and BTB. Using a large suite of recently released industrial traces, we show that predictive replacement policies can reduce misses in the I-cache and BTB. We introduce Global History Reuse Prediction (GHRP), a replacement technique that uses the history of past instruction addresses and their reuse behaviors to predict dead blocks in the I-cache and dead entries in the BTB. This paper describes the effectiveness of GHRP as a dead block replacement and bypass optimization for both the I-cache and BTB. For a 64KB set-associative I-cache with a 64B block size, GHRP lowers the I-cache misses per 1000 instructions (MPKI) by an average of 18{\%} over the least-recently-used (LRU) policy on a set of 662 industrial workloads, performing significantly better than Static Re-reference Interval Prediction (SRRIP) [1] and Sampling Dead Block Prediction (SDBP)[2]. For a 4K-entry BTB, GHRP lowers MPKI by an average of 30{\%} over LRU, 23{\%} over SRRIP, and 29{\%} over SDBP.},
author = {Ajorpaz, Samira Mirbagher and Garza, Elba and Jindal, Sangam and Jim{\'{e}}nez, Daniel A.},
booktitle = {Proceedings - International Symposium on Computer Architecture},
doi = {10.1109/ISCA.2018.00050},
issn = {10636897},
title = {{Exploring predictive replacement policies for instruction cache and branch target buffer}},
year = {2018}
}
@inproceedings{Lavaee2019,
abstract = {Modern software executes a large amount of code. Previous techniques of code layout optimization were developed one or two decades ago and have become inadequate to cope with the scale and complexity of new types of applications such as compilers, browsers, interpreters, language VMs and shared libraries. This paper presents Codestitcher, an inter-procedural basic block code layout optimizer which reorders basic blocks in an executable to benefit from better cache and TLB performance. Codestitcher provides a hierarchical framework which can be used to improve locality in various layers of the memory hierarchy. Our evaluation shows that Codestitcher improves the performance of the original program (already optimized with O3 and link time optimizations) by 3{\%} to 25{\%} (on average, by 10{\%}) on 5 widely used applications with large code sizes: MySQL, Clang, Firefox, PHP server, and Python. It gives an additional improvement of 4{\%} over LLVM's PGO and 3{\%} over PGO combined with the best function reordering technique. For profiling, Codestitcher does not need instrumentation. Instead it uses branch history samples which are collected during the execution of the original program. Codestitcher's profiling and trace processing together incur an average overhead of 22.5{\%}, compared to an average overhead of 90{\%} from LLVM's PGO.},
author = {Lavaee, Rahman and Criswell, John and Ding, Chen},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3302516.3307358},
title = {{Codestitcher: Inter-procedural basic block layout optimization}},
year = {2019}
}
@inproceedings{Zhou2019,
abstract = {We present Janus, a framework that addresses the challenge of automatic binary parallelisation. Janus uses same-ISA dynamic binary modification to optimise application binaries, controlled by static analysis with judicious use of software speculation and runtime checks that ensure the safety of the optimisations. A static binary analyser first examines a binary executable, to determine the loops that are amenable to parallelisation and the transformations required. These are encoded as a series of rewrite rules, the steps needed to convert a serial loop into parallel form. The Janus dynamic binary modifier reads both the original executable and rewrite rules and carries out the transformations on a per-basic-block level just-in-time before execution. Lifting static analysis out of the runtime enables the global and profile-guided views of the application; ambiguities from static binary analysis can in turn be addressed through a combination of dynamic runtime checks and speculation guard against data dependence violations. It allows us to parallelise even those loops containing dynamically discovered code. We demonstrate Janus by parallelising a range of optimised SPEC CPU 2006 benchmarks, achieving average speedups of 2.1$\backslash$times and 6.0$\backslash$times in the best case.},
author = {Zhou, Ruoyu and Jones, Timothy M.},
booktitle = {CGO 2019 - Proceedings of the 2019 IEEE/ACM International Symposium on Code Generation and Optimization},
doi = {10.1109/CGO.2019.8661196},
title = {{Janus: Statically-Driven and Profile-Guided Automatic Dynamic Binary Parallelisation}},
year = {2019}
}
@inproceedings{Zhou2021,
abstract = {Developing efficient GPU kernels can be difficult because of the complexity of GPU architectures and programming models. Existing performance tools only provide coarse-grained tuning advice at the kernel level, if any. In this paper, we describe GPA, a performance advisor for NVIDIA GPUs that suggests potential code optimizations at a hierarchy of levels, including individual lines, loops, and functions. To relieve users of the burden of interpreting performance counters and analyzing bottlenecks, GPA uses data flow analysis to approximately attribute measured instruction stalls to their root causes and uses information about a program's structure and the GPU to match inefficiency patterns with optimization strategies. To quantify the potential benefits of each optimization strategy, we developed PC sampling-based performance models to estimate its speedup. Our experiments with benchmarks and applications show that GPA provides insightful reports to guide performance optimization. Using GPA, we obtained speedups on a Volta V100 GPU ranging from 1.01 x to 3.58 ×, with a geometric mean of 1.22 x.},
author = {Zhou, Keren and Meng, Xiaozhu and Sai, Ryuichi and Mellor-Crummey, John},
booktitle = {CGO 2021 - Proceedings of the 2021 IEEE/ACM International Symposium on Code Generation and Optimization},
doi = {10.1109/CGO51591.2021.9370339},
title = {{GPA: A GPU Performance Advisor Based on Instruction Sampling}},
year = {2021}
}
@inproceedings{Lattner2004,
abstract = {This paper describes LLVM (Low Level Virtual Machine), a compiler framework designed to support transparent, life-long program analysis and transformation for arbitrary programs, by providing high-level information to compiler transformations at compile-time, link-time, run-time, and in idle time between runs. LLVM defines a common, low-level code representation in Static Single Assignment (SSA) form, with several novel features: a simple, language-independent type-system that exposes the primitives commonly used to implement high-level language features; an instruction for typed address arithmetic; and a simple mechanism that can be used to implement the exception handling features of high-level languages (and setjmp/longjmp in C) uniformly and efficiently. The LLVM compiler framework and code representation together provide a combination of key capabilities that are important for practical, lifelong analysis and transformation of programs. To our knowledge, no existing compilation approach provides all these capabilities. We describe the design of the LLVM representation and compiler framework, and evaluate the design in three ways: (a) the size and effectiveness of the representation, including the type information it provides; (b) compiler performance for several interprocedural problems; and (c) illustrative examples of the benefits LLVM provides for several challenging compiler problems.},
author = {Lattner, Chris and Adve, Vikram},
booktitle = {International Symposium on Code Generation and Optimization, CGO},
doi = {10.1109/CGO.2004.1281665},
title = {{LLVM: A compilation framework for lifelong program analysis {\&} transformation}},
year = {2004}
}
@inproceedings{Holzle1994,
abstract = {Object-oriented programs are difficult to optimize because they execute many dynamically-dispatched calls. These calls cannot easily be eliminated because the compiler does not know which callee will be invoked at runtime. We have developed a simple technique that feeds back type information from the runtime system to the compiler. With this type feedback, the compiler can inline any dynamically-dispatched call. Our compiler drastically reduces the call frequency of a suite of large SELF applications (by a factor of 3.6) and improves performance by a factor of 1.7. We believe that type feedback could significantly reduce call frequencies and improve performance for most other object-oriented languages (statically-typed or not) as well as for languages with type-dependent operations such as generic arithmetic.},
author = {Holzle, Urs and Ungar, David},
booktitle = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
doi = {10.1145/178243.178478},
title = {{Optimizing dynamically-dispatched calls with run-time type feedback}},
year = {1994}
}
@article{Li2007,
abstract = {Dynamic binary translator is a just-in-time compiler, which translates the instructions of source architecture to the instructions of target architecture when an application is running. The technology enables the application compiled for source architecture running on top of target architecture without recompilation. This paper begins with the basic framework of dynamic binary translator, and then gives an overview of several leading dynamic binary translators. After that, it has a deep discussion about key challenges of the dynamic binary translator, including supporting precise exception in optimized code, mapping source architectural context to target architectural context, translating self modifying code, reducing translation overhead, and dynamic optimization using profiling data. The paper ends with the hot research topics and possible usage models of the dynamic binary translation technology.},
author = {Li, Jianhui and Ma, Xiangning and Zhu, Chuanqi},
doi = {10.1360/crad20070123},
issn = {10001239},
journal = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
number = {1},
title = {{Dynamic binary translation and optimization}},
volume = {44},
year = {2007}
}
@inproceedings{Bruening2003,
abstract = {Dynamic optimization is emerging as a promising approach to overcome many of the obstacles of traditional static compilation. But while there are a number of compiler infrastructures for developing static optimizations, there are very few for developing dynamic optimizations. We present a framework for implementing dynamic analyses and optimizations. We provide an interface for building external modules, or clients, for the DynamoRIO dynamic code modification system. This interface abstracts away many low-level details of the DynamoRIO runtime system while exposing a simple and powerful, yet efficient and lightweight API. This is achieved by restricting optimization units to linear streams of code and using adaptive levels of detail for representing instructions. The interface is not restricted to optimization and can be used for instrumentation, profiling, dynamic translation, etc. To demonstrate the usefulness and effectiveness of our framework, we implemented several optimizations. These improve the performance of some applications by as much as 40{\%} relative to native execution. The average speedup relative to base DynamoRIO performance is 12{\%}.},
author = {Bruening, D. and Garnett, T. and Amarasinghe, S.},
booktitle = {International Symposium on Code Generation and Optimization, CGO 2003},
doi = {10.1109/CGO.2003.1191551},
title = {{An infrastructure for adaptive dynamic optimization}},
year = {2003}
}
@inproceedings{Lin2016,
abstract = {Control Flow Integrity (CFI) is an attractive security property with which most injected and code reuse attacks can be defeated, including advanced attacking techniques like Return-Oriented Programming (ROP). However, comprehensive enforcement of CFI is expensive due to additional supports needed (e.g., compiler support and presence of relocation or debug information) and performance overhead. Recent research has been trying to strike the balance among reasonable approximation of the CFI properties, minimal additional supports needed, and acceptable performance. We investigate existing dynamic code optimization techniques and find that they provide an architecture on which CFI can be enforced effectively and efficiently. In this paper, we propose and implement DynCFI that enforces security policies on a well established dynamic optimizer and show that it provides comparable CFI properties with existing CFI implementations while lowering the overall performance overhead from 28.6{\%} to 14.8{\%}. We further perform comprehensive evaluations and shed light on the exact amount of savings contributed by the various components of the dynamic optimizer including basic block cache, trace cache, branch prediction, and indirect branch lookup.},
author = {Lin, Yan and Tang, Xiaoxiao and Gao, Debin and Fu, Jianming},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-45871-7_22},
issn = {16113349},
title = {{Control flow integrity enforcement with dynamic code optimization}},
volume = {9866 LNCS},
year = {2016}
}
@article{Vandeputte2007,
abstract = {Energy consumption is a major design issue for modern microprocessors. In previous work, several techniques were presented to reduce the overall energy consumption by dynamically adapting various hardware structures. Most approaches however lack the ability to deal efficiently with the configuration space explosion in case of multiple adaptive structures. In this paper, we present a mechanism that is able to deal with this configuration space problem. We first identify phases through profiling using a new phase classification method and determine the optimal hardware configuration per phase using an efficient offline search algorithm. During program execution, we inspect the phase behavior and adapt the hardware on a per-phase basis. Using SPEC2000 benchmarks, we show that the proposed mechanism achieves an energy reduction of 36{\%} on average with an average performance degradation of only 2.9{\%}. We also show that online processor configuration optimization is far less effective for multi-configuration processors, with an average energy reduction of less than 20{\%} for comparable performance degradations. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Vandeputte, Frederik and Eeckhout, Lieven and {De Bosschere}, Koen},
doi = {10.1016/j.sysarc.2006.11.004},
issn = {13837621},
journal = {Journal of Systems Architecture},
number = {8},
title = {{Exploiting program phase behavior for energy reduction on multi-configuration processors}},
volume = {53},
year = {2007}
}
@inproceedings{Lebras2019,
abstract = {Modern high performance processor architectures /tackle performance issues by heavily relying on increased vector lengths and advanced memory hierarchies to deliver high performance. This stresses the importance of data access optimization and efficient usage of the underlying hardware. Developers usually trust compilers to automatically address these performance issues, but unfortunately, compilers deploy static performance models and heuristics which, sometimes, remain conservative or even fail in the worst case. Moreover, manual optimization of production HPC codes is not only impractical, but impossible when having to manage multiple architecture dependent transformations. One way to assist compilers is to use Profile Guided Optimization (PGO). It allows the use of feedback data from dynamic profiling using a representative training dataset, for a given target application, enabling the compiler to refine its optimization choices and enhance application performance. But, PGO does not always consider certain metrics and is rarely aggressive enough regarding metric data collection. This bounds the transformation space and limits the compiler's ability to perform further optimizations. An additional option is to provide compilers with user guided assistance in order to enlarge the transformation space (i.e. specialization) and enhance the quality of optimizations.In this paper, we introduce ASSIST, a semi-automatic sourceto-source manipulation taking advantage of static and dynamic profiling data produced by performance analysis tools. We demonstrate on real industrial class applications that by combining both static and dynamic analyses and by deploying simple transformations, ASSIST generates similar (and in some cases higher) performance speedups than Intel PGO. Furthermore, combining ASSIST and PGO allows to go a step further, increasing the performance substantially.},
author = {Lebras, Youenn and Charif-Rubial, Andres S. and Jalby, William},
booktitle = {2019 International Conference on High Performance Computing and Simulation, HPCS 2019},
doi = {10.1109/HPCS48598.2019.9188161},
title = {{Combining static and dynamic analysis to guide PGO for HPC applications: A case study on real-world applications}},
year = {2019}
}
@inproceedings{Ying2020,
abstract = {Multicores are now ubiquitous, but programmers still write sequential code. Speculative parallelization is an enticing approach to parallelize code while retaining the ease of sequential programming, making parallelism pervasive. However, prior speculative parallelizing compilers and architectures achieved limited speedups due to high costs of recovering from misspeculation and hardware scalability bottlenecks. We present T4, a parallelizing compiler that successfully leverages recent hardware features for speculative execution, which present new opportunities and challenges for automatic parallelization. T4 transforms sequential programs into trees of tiny timestamped tasks. T4 introduces novel compiler techniques to expose parallelism aggressively across the entire program, breaking applications into tiny tasks of tens of instructions each. Task trees unfold their branches in parallel to enable high task-spawn throughput while exploiting selective aborts to recover from misspeculation cheaply. T4 exploits parallelism across function calls, loops, and loop nests; performs new transformations to reduce task spawn costs and avoid false sharing; and exploits data locality among fine-grain tasks. As a result, T4 scales several hard-to-parallelize SPECCPU2006 benchmarks to tens of cores, on which prior work attained little or no speedup.},
author = {Ying, Victor A. and Jeffrey, Mark C. and Sanchez, Daniel},
booktitle = {Proceedings - International Symposium on Computer Architecture},
doi = {10.1109/ISCA45697.2020.00024},
issn = {10636897},
title = {{T4: Compiling Sequential Code for Effective Speculative Parallelization in Hardware}},
volume = {2020-May},
year = {2020}
}
@inproceedings{Nethercote2003,
abstract = {Valgrind is a programmable framework for creating program supervision tools such as bug detectors and profilers. It executes supervised programs using dynamic binary translation, giving it total control over their every part without requiring source code, and without the need for recompilation or relinking prior to execution. New supervision tools can be easily created by writing skins that plug into Valgrind's core. As an example, we describe one skin that performs Purify-style memory checks for C and C++ programs. {\textcopyright} 2003 Published by Elsevier Science B.V.},
author = {Nethercote, Nicholas and Seward, Julian},
booktitle = {Electronic Notes in Theoretical Computer Science},
doi = {10.1016/S1571-0661(04)81042-9},
issn = {15710661},
number = {2},
title = {{Valgrind: A program supervision framework}},
volume = {89},
year = {2003}
}
@article{Ovasapyan2020,
abstract = {Abstract: The application of taint analysis to increase the efficiency of safety analysis of the software used by Internet-of-Things devices based on the ARM architecture is considered. A comparison of the existing dynamic instrumentation is made. As a result, we identified the most acceptable solution for the problem. The functionality of the selected tool has been refined in order to improve the efficiency of analyzing the influence of input data on the operation of the software under study.},
author = {Ovasapyan, T. D. and Knyazev, P. V. and Moskvin, D. A.},
doi = {10.3103/S0146411620080246},
issn = {1558108X},
journal = {Automatic Control and Computer Sciences},
number = {8},
title = {{Application of Taint Analysis to Study the Safety of Software of the Internet of Things Devices Based on the ARM Architecture}},
volume = {54},
year = {2020}
}
@inproceedings{Chen2016,
abstract = {AutoFDO is a system to simplify real-world deployment of feedback-directed optimization (FDO). The system works by sampling hardware performance monitors on production machines and using those profiles to guide optimization. Profile data is stale by design, and we have implemented compiler features to deliver stable speedup across releases. The resulting performance has a geometric mean improvement of 10.5 The system is deployed to hundreds of binaries at Google, and it is extremely easy to enable; users need only to add some flags to their release build. To date, AutoFDO has increased the number of FDO users at Google by 8X and has doubled the number of cycles spent in FDO-optimized binaries. Over half of CPU cycles used are now spent in some flavor of FDO-optimized binaries.},
author = {Chen, Dehao and Li, David Xinliang and Moseley, Tipp},
booktitle = {Proceedings of the 14th International Symposium on Code Generation and Optimization, CGO 2016},
doi = {10.1145/2854038.2854044},
title = {{AutoFDO: Automatic feedback-directed optimization for warehouse-scale applications}},
year = {2016}
}
@incollection{Lin2021,
abstract = {Prior to the introduction of CFI in 2005, there have already been a lot of research on dynamic code optimization to improve performance of dynamic program interpreters. For example, Wiggins/Redstone [1], Dynamo [2], Mojo [3], and DynamoRIO [4].},
author = {Lin, Yan},
booktitle = {Information Security and Cryptography},
doi = {10.1007/978-3-030-73141-0_5},
issn = {2197845X},
title = {{Control-flow integrity enforcement with dynamic code optimization}},
year = {2021}
}
@inproceedings{Khan2020,
abstract = {Modern data center applications have rapidly expanding instruction footprints that lead to frequent instruction cache misses, increasing cost and degrading data center performance and energy efficiency. Mitigating instruction cache misses is challenging since existing techniques (1) require significant hardware modifications, (2) expect impractical on-chip storage, or (3) prefetch instructions based on inaccurate understanding of program miss behavior. To overcome these limitations, we first investigate the challenges of effective instruction prefetching. We then use insights derived from our investigation to develop I-SPY, a novel profiledriven prefetching technique. I-SPY uses dynamic miss profiles to drive an offline analysis of I-cache miss behavior, which it uses to inform prefetching decisions. Two key techniques underlie ISPY's design: (1) conditional prefetching, which only prefetches instructions if the program context is known to lead to misses, and (2) prefetch coalescing, which merges multiple prefetches of noncontiguous cache lines into a single prefetch instruction. I-SPY exposes these techniques via a family of light-weight hardware code prefetch instructions. We study I-SPY in the context of nine data center applications and show that it provides an average of 15.5{\%} (up to 45.9{\%}) speedup and 95.9{\%} (and up to 98.4{\%}) reduction in instruction cache misses, outperforming the state-of-the-art prefetching technique by 22.5{\%}. We show that I-SPY achieves performance improvements that are on average 90.5{\%} of the performance of an ideal cache with no misses.},
author = {Khan, Tanvir Ahmed and Sriraman, Akshitha and Devietti, Joseph and Pokam, Gilles and Litz, Heiner and Kasikci, Baris},
booktitle = {Proceedings of the Annual International Symposium on Microarchitecture, MICRO},
doi = {10.1109/MICRO50266.2020.00024},
issn = {10724451},
title = {{I-SPY: Context-driven conditional instruction prefetching with coalescing}},
volume = {2020-Octob},
year = {2020}
}
@inproceedings{Kalla2017,
abstract = {Branch prediction is crucial in improving the throughput of microprocessors. It reduces branching stalls in the pipeline, which helps to maintain the instruction execution flow. Of these instructions, conditional branches are non-Trivial in determining the microprocessor performance and throughput. Modern microprocessors accurately predict the branches using advanced branch prediction techniques. Appropriately estimating the branch mis-predictions benefits to improve the overall performance of an application through effectively saving the CPU cycles. In general, collecting branch prediction statistics using state-of-The-Art simulators is time consuming and not scalable. We present a novel Monte Carlo simulation framework that predicts branch mis-prediction rate. Our framework produces results that suggest that the mis-prediction rates on three scientific applications are similar (with an average difference of 0.3{\%}) to that of a Markov model of a 2-bit saturating branch predictor.},
author = {Kalla, Bhargava and Santhi, Nandakishore and Badawy, Abdel Hameed A. and Chennupati, Gopinath and Eidenbenz, Stephan},
booktitle = {Proceedings - IEEE International Conference on Cluster Computing, ICCC},
doi = {10.1109/CLUSTER.2017.29},
issn = {15525244},
title = {{A Probabilistic Monte Carlo Framework for Branch Prediction}},
volume = {2017-Septe},
year = {2017}
}
